{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEPOOL IDR Drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements class to batch tasks used for IDR drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IDRdrop\n",
    "import EPOwebscrape\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bodies.json', 'r') as f:\n",
    "    bodies = json.load(f)\n",
    "\n",
    "bodies = json.loads(bodies)\n",
    "\n",
    "#print(bodies.keys())\n",
    "for item in bodies.values():\n",
    "    print(item['accts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'SUEZ' in 'SUEZ_HIST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files from EPO portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser, url = logon('somer-nengie', 'rb4171', False)\n",
    "\n",
    "browser, url = EPOwebscrape.logon('SUEZ_HIST', '3824', True)\n",
    "\n",
    "accts_to_find = ['0040677012', '0021483009']\n",
    "#accts_to_find = ['0040677012', '0021483009', '0067880031', '0074816023'] #enter accts as list\n",
    "#accts_to_find = ['28905980018', '26121881010']\n",
    "AIDs = []\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source)\n",
    "table = soup.find('tbody', {'role' : 'rowgroup'})\n",
    "\n",
    "#get EPO AID value for every account\n",
    "for accts in accts_to_find:\n",
    "    results = EPOwebscrape.big_match(accts, table)\n",
    "    AIDs.append(results)\n",
    "\n",
    "#make list of AIDs, split into list of lists of 5\n",
    "final = []\n",
    "AIDs\n",
    "\n",
    "for aid_list in AIDs:\n",
    "    for aid in aid_list:\n",
    "        final.append(aid)\n",
    "\n",
    "n = 5\n",
    "final2 = [final[i * n:(i + 1) * n] for i in range((len(final) + n - 1) // n )]  \n",
    "final2\n",
    "\n",
    "for elem in final2:\n",
    "    EPOwebscrape.export_data(elem, browser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show downloaded files from EPO portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here *filepath* is a directory containing downloaded EPO files. Code will print 20 most recent files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files found in dir:  C:\\Users\\wb5888\\Downloads\n",
      "                                                files                time\n",
      "0   eversource_0ae4037b-a439-4537-a57f-2bbce974f91... 2019-05-30 11:44:41\n",
      "1                           GSOutput1559233784189.xls 2019-05-30 11:30:24\n",
      "2                           GSOutput1559233364653.xls 2019-05-30 11:24:06\n",
      "3                     IntervalData_05292019151637.csv 2019-05-29 15:16:39\n",
      "4     20190529131105132000_NEPOOL_NRI_7716801014.json 2019-05-29 13:16:12\n",
      "5                           GSOutput1559151547077.xls 2019-05-29 12:40:21\n",
      "6                     IntervalData_05292019120416.csv 2019-05-29 12:04:19\n",
      "7   ngrid_f968810a-266f-448e-b92a-5c49b74547cf_6ec... 2019-05-29 11:16:07\n",
      "8                     IntervalData_05292019103321.csv 2019-05-29 10:33:24\n",
      "9   eversource_2843223a-43e1-4b37-82a7-5a0bcf1f3dc... 2019-05-29 09:46:11\n",
      "10  eversource_2843223a-43e1-4b37-82a7-5a0bcf1f3dc... 2019-05-29 09:45:56\n",
      "11  eversource_2843223a-43e1-4b37-82a7-5a0bcf1f3dc... 2019-05-29 09:45:42\n",
      "12                                         README.pdf 2019-05-29 09:05:21\n",
      "13                                          README.md 2019-05-29 08:58:33\n",
      "14                                        desktop.ini 2019-05-29 07:16:05\n",
      "15                    IntervalData_05282019153400.csv 2019-05-28 15:34:03\n",
      "16                    IntervalData_05282019141824.csv 2019-05-28 14:18:28\n",
      "17                    IntervalData_05282019140509.csv 2019-05-28 14:05:13\n",
      "18                    IntervalData_05282019102335.csv 2019-05-28 10:23:39\n",
      "19                    IntervalData_05282019092154.csv 2019-05-28 09:21:57\n"
     ]
    }
   ],
   "source": [
    "#filepath = os.getcwd()\n",
    "readpath = 'C:\\\\Users\\\\wb5888\\\\Downloads'\n",
    "\n",
    "myfiles = IDRdrop.show_dir(readpath, 20)\n",
    "print(myfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose files to split into Raw IDR files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files to split: \n",
      "['eversource_0ae4037b-a439-4537-a57f-2bbce974f91c_f77091a8_hourlycsv.csv']\n"
     ]
    }
   ],
   "source": [
    "index = [0]\n",
    "\n",
    "splitfiles = list(myfiles.files[index])\n",
    "print('files to split: ')\n",
    "print(splitfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process downloaded EPO files into Raw IDRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-06fad34695b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfiledf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mIDRdrop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiledf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreadpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwritepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'success, file: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python_Code\\IDR_Drop\\IDRdrop.py\u001b[0m in \u001b[0;36mraw_split\u001b[1;34m(filedf, readdir, writedir)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mutil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macct_from_LDC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mwritedir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwritedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: join() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "readpath = 'C:\\\\Users\\\\wb5888\\\\Downloads'\n",
    "writepath = 'C:\\\\Users\\\\wb5888\\\\Documents\\\\Raw IDR Data\\\\NEPOOL'\n",
    "error_log = []\n",
    "\n",
    "for file in splitfiles:\n",
    "    try:\n",
    "        os.chdir(readpath)\n",
    "        filedf = pd.read_csv(file, sep = \",\", header = 0)\n",
    "    \n",
    "        IDRdrop.raw_split(filedf, readpath, writepath)\n",
    "        print('success, file: ', file)\n",
    "        \n",
    "    except:\n",
    "        error_log = error_log.append(file)\n",
    "        print('error, file: ', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Raw IDR files based on utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility = \"COMELEC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here *rawpath* is directory containing Raw IDRs - 25 most recent will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawpath = 'C:\\\\Users\\\\wb5888\\\\Documents\\\\Raw IDR Data\\\\NEPOOL\\\\' + utility\n",
    "\n",
    "rawfiles = IDRdrop.show_dir(rawpath, 25)\n",
    "print(rawfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Raw IDRs to filter into IDR files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [36]\n",
    "\n",
    "processfiles = list(rawfiles.files[:21])\n",
    "print('files to processed: ')\n",
    "print(processfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch filter Raw IDR into IDR files to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readpath = rawpath\n",
    "writepath = 'C:\\\\Users\\\\wb5888\\\\Documents\\\\IDR Data\\\\NEPOOL\\\\'\n",
    "error_log = []\n",
    "\n",
    "for dropfile in processfiles:\n",
    "    try:\n",
    "        IDRdrop.data_drop(dropfile, rawpath, writepath)\n",
    "        print('success, file: ', dropfile)\n",
    "    \n",
    "    except:\n",
    "        error_log.append(dropfile)\n",
    "        print(\"error, file: \", dropfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(EPOwebscrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
