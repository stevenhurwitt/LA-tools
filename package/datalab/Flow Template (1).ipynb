{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalab Flow Retrieval and Visualization\n",
    "\n",
    "This simple notebook provides a template for retrieving flow data using eQL, visualizing the results and saving as a .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we import our notebook tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T20:45:09.898637Z",
     "start_time": "2019-07-19T20:45:09.890744Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from energyworx_client.client import EWX\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, pick your namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T20:45:13.817099Z",
     "start_time": "2019-07-19T20:45:13.765226Z"
    }
   },
   "outputs": [],
   "source": [
    "namespace = 'na.engie.com'\n",
    "api = EWX(namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your flow query\n",
    "\n",
    "Note that you need to add your desired flow ID into the query. The flow ID is easily found using the console (click the dropdown tab for the flow details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T19:04:17.778396Z",
     "start_time": "2018-12-13T19:04:17.767557Z"
    }
   },
   "outputs": [],
   "source": [
    "#example of extracting usage\n",
    "#flow_query = \"SELECT STRUCT(timestamp, STRUCT(flow_id, ARRAY[STRUCT(channel_classifier_id, value, \\\n",
    "#              ARRAY(SELECT AS STRUCT annotation, sequence_id, ARRAY_AGG(STRUCT(key, value))))] AS channel) AS flow) AS row \\\n",
    "#              FROM flows WHERE flow_id IN ('{flow_id}') \\\n",
    "#              AND timestamp > '{start_timestamp}' AND timestamp <= '{end_timestamp}' \\\n",
    "#              GROUP BY timestamp, flow_id, channel_classifier_id, value ORDER BY timestamp, flow_id \"\n",
    "#        \n",
    "#timeseries_df = api.execute_query(flow_query.format( flow_id='7cd20c8e088a48c6a65e3dcee069d3b0', start_timestamp='2018-01-01T00:00:00', end_timestamp='2030-01-01T00:00:00')\n",
    "#, limit=50000)\n",
    "#timeseries_df.head()`\n",
    "\n",
    "#documentation for api.execute_query()\n",
    "#print(api.execute_query.__doc__) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T20:48:20.791092Z",
     "start_time": "2019-07-19T20:48:05.968158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasource_id</th>\n",
       "      <th>flow_timestamp</th>\n",
       "      <th>flow_type</th>\n",
       "      <th>channel_classifier_id</th>\n",
       "      <th>flow_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEPOOL_CLP_51936044007_533192008</td>\n",
       "      <td>2018-01-02 13:31:29.384260</td>\n",
       "      <td>scenario</td>\n",
       "      <td>DELIVERY_IDR</td>\n",
       "      <td>548d4d2c36eb422087efbf010515d70a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEPOOL_WMECO_54472602028_018741009</td>\n",
       "      <td>2018-01-02 13:36:25.125888</td>\n",
       "      <td>scenario</td>\n",
       "      <td>DELIVERY_SCALAR</td>\n",
       "      <td>74412323c4f24267a1e851cd176a66a8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERCOT_ONCOR_10443720000437140</td>\n",
       "      <td>2018-01-02 13:55:02.645628</td>\n",
       "      <td>scenario</td>\n",
       "      <td>DELIVERY_SCALAR</td>\n",
       "      <td>dff0af511dc94df4b6bcd73b7a87a723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERCOT_ONCOR_10443720001104315</td>\n",
       "      <td>2018-01-02 13:55:15.721216</td>\n",
       "      <td>scenario</td>\n",
       "      <td>DELIVERY_SCALAR</td>\n",
       "      <td>a4a1966e008e40afb0758f328743bfc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERCOT_ONCOR_10443720001003229</td>\n",
       "      <td>2018-01-02 14:08:00.754024</td>\n",
       "      <td>scenario</td>\n",
       "      <td>DELIVERY_IDR</td>\n",
       "      <td>26186a8ef9db4f619acb972010f1599c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datasource_id             flow_timestamp flow_type  \\\n",
       "0    NEPOOL_CLP_51936044007_533192008 2018-01-02 13:31:29.384260  scenario   \n",
       "1  NEPOOL_WMECO_54472602028_018741009 2018-01-02 13:36:25.125888  scenario   \n",
       "2       ERCOT_ONCOR_10443720000437140 2018-01-02 13:55:02.645628  scenario   \n",
       "3       ERCOT_ONCOR_10443720001104315 2018-01-02 13:55:15.721216  scenario   \n",
       "4       ERCOT_ONCOR_10443720001003229 2018-01-02 14:08:00.754024  scenario   \n",
       "\n",
       "  channel_classifier_id                           flow_id  \n",
       "0          DELIVERY_IDR  548d4d2c36eb422087efbf010515d70a  \n",
       "1       DELIVERY_SCALAR  74412323c4f24267a1e851cd176a66a8  \n",
       "2       DELIVERY_SCALAR  dff0af511dc94df4b6bcd73b7a87a723  \n",
       "3       DELIVERY_SCALAR  a4a1966e008e40afb0758f328743bfc8  \n",
       "4          DELIVERY_IDR  26186a8ef9db4f619acb972010f1599c  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "timeseries_df = []\n",
    "\n",
    "#example of extracting latest datasource ids \n",
    "flow_query = \"Select datasource_id,flow_timestamp,flow_type,channel_classifier_id,flow_id from flow_metadata where flow_timestamp > '2018-01-01T00:00:00' ORDER BY flow_timestamp\"\n",
    "timeseries_df = api.execute_query(flow_query,limit = 10, raw_result = True)\n",
    "\n",
    "#process resulting dictionary\n",
    "kdatasource  = pd.DataFrame()\n",
    "LENK = len(list(timeseries_df['rows']))\n",
    "for k in range(0,LENK):\n",
    "    kdatasource.loc[k,\"datasource_id\"] = list(timeseries_df['rows'])[k]['f'][0]['v']\n",
    "    ktimestamp = list(timeseries_df['rows'])[k]['f'][1]['v']\n",
    "    kdate = datetime.datetime.fromtimestamp(float(ktimestamp))\n",
    "    kdatasource.loc[k,\"flow_timestamp\"] =  kdate\n",
    "    kdatasource.loc[k,\"flow_type\"] =  list(timeseries_df['rows'])[k]['f'][2]['v']\n",
    "    kdatasource.loc[k,\"channel_classifier_id\"] =  list(timeseries_df['rows'])[k]['f'][3]['v']\n",
    "    kdatasource.loc[k,\"flow_id\"] =  list(timeseries_df['rows'])[k]['f'][4]['v']\n",
    "kdatasource.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T17:13:19.646110Z",
     "start_time": "2019-06-24T17:13:19.301686Z"
    }
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://ewx-live.appspot.com/_ah/api/ewx/v1/query/execute?query=SELECT+timestamp%2C+ARRAY%5BSTRUCT%28channel+AS+channel_classifier%2C+value+AS+value%29%5D+AS+raw+++++++++++++++FROM+INGEST+WHERE+timestamp+%3E+%272016-10-08T10%3A00%3A00%27+AND+timestamp+%3C%3D+%272018-09-14T00%3A00%3A01%27+AND+datasource_id+IN+%28%27KADW%27%29+AND+channel_classifier_id+IN+%28%27AIRTEMPERATURE%27%29+++++++++++++++GROUP+BY+timestamp%2C+channel%2C+value+ORDER+BY+timestamp+asc+&alt=json&limit=10 returned \"Datasource with id KADW was not found\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-257f75115cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflow_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT timestamp, ARRAY[STRUCT(channel AS channel_classifier, value AS value)] AS raw               FROM INGEST WHERE timestamp > '2016-10-08T10:00:00' AND timestamp <= '2018-09-14T00:00:01' AND datasource_id IN ('KADW') AND channel_classifier_id IN ('AIRTEMPERATURE')               GROUP BY timestamp, channel, value ORDER BY timestamp asc \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtimeseries_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/energyworx_client/client.pyc\u001b[0m in \u001b[0;36mexecute_query\u001b[0;34m(self, query, job_id, limit, page_token, raw_result)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjob_complete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpageToken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__execute_and_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mjob_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jobComplete'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jobId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/energyworx_client/client.pyc\u001b[0m in \u001b[0;36m__execute_and_handle_response\u001b[0;34m(self, request, async)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msocket_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msocket_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Connection reset by peer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/oauth2client/util.pyc\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/googleapiclient/http.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://ewx-live.appspot.com/_ah/api/ewx/v1/query/execute?query=SELECT+timestamp%2C+ARRAY%5BSTRUCT%28channel+AS+channel_classifier%2C+value+AS+value%29%5D+AS+raw+++++++++++++++FROM+INGEST+WHERE+timestamp+%3E+%272016-10-08T10%3A00%3A00%27+AND+timestamp+%3C%3D+%272018-09-14T00%3A00%3A01%27+AND+datasource_id+IN+%28%27KADW%27%29+AND+channel_classifier_id+IN+%28%27AIRTEMPERATURE%27%29+++++++++++++++GROUP+BY+timestamp%2C+channel%2C+value+ORDER+BY+timestamp+asc+&alt=json&limit=10 returned \"Datasource with id KADW was not found\">"
     ]
    }
   ],
   "source": [
    "flow_query = \"SELECT timestamp, ARRAY[STRUCT(channel AS channel_classifier, value AS value)] AS raw \\\n",
    "              FROM INGEST WHERE timestamp > '2016-10-08T10:00:00' AND timestamp <= '2018-09-14T00:00:01' AND datasource_id IN ('KADW') AND channel_classifier_id IN ('AIRTEMPERATURE') \\\n",
    "              GROUP BY timestamp, channel, value ORDER BY timestamp asc \"\n",
    "\n",
    "timeseries_df = api.execute_query(flow_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T22:35:48.471536Z",
     "start_time": "2018-12-13T22:35:48.437343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRTEMPERATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-08 10:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 11:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 12:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 13:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 14:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 15:00:00</th>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 16:00:00</th>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 17:00:00</th>\n",
       "      <td>18.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 18:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 19:00:00</th>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 20:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 21:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 22:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-08 23:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 00:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 01:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 02:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 03:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 04:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 05:00:00</th>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 06:00:00</th>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 07:00:00</th>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 08:00:00</th>\n",
       "      <td>13.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 09:00:00</th>\n",
       "      <td>12.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 10:00:00</th>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 11:00:00</th>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 12:00:00</th>\n",
       "      <td>11.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 13:00:00</th>\n",
       "      <td>12.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 14:00:00</th>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09 15:00:00</th>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 19:00:00</th>\n",
       "      <td>27.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 20:00:00</th>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 21:00:00</th>\n",
       "      <td>27.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 22:00:00</th>\n",
       "      <td>26.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 23:00:00</th>\n",
       "      <td>25.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 00:00:00</th>\n",
       "      <td>24.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 01:00:00</th>\n",
       "      <td>23.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 02:00:00</th>\n",
       "      <td>23.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 03:00:00</th>\n",
       "      <td>23.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 04:00:00</th>\n",
       "      <td>23.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 05:00:00</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 06:00:00</th>\n",
       "      <td>22.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 07:00:00</th>\n",
       "      <td>22.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 08:00:00</th>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 09:00:00</th>\n",
       "      <td>22.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 10:00:00</th>\n",
       "      <td>22.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 11:00:00</th>\n",
       "      <td>22.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 12:00:00</th>\n",
       "      <td>22.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 13:00:00</th>\n",
       "      <td>22.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 14:00:00</th>\n",
       "      <td>23.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 15:00:00</th>\n",
       "      <td>23.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 16:00:00</th>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 17:00:00</th>\n",
       "      <td>24.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 18:00:00</th>\n",
       "      <td>25.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 19:00:00</th>\n",
       "      <td>25.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 20:00:00</th>\n",
       "      <td>25.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 21:00:00</th>\n",
       "      <td>25.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 22:00:00</th>\n",
       "      <td>25.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 23:00:00</th>\n",
       "      <td>24.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-14 00:00:00</th>\n",
       "      <td>24.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16935 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AIRTEMPERATURE\n",
       "2016-10-08 10:00:00           17.22\n",
       "2016-10-08 11:00:00           17.22\n",
       "2016-10-08 12:00:00           17.22\n",
       "2016-10-08 13:00:00           17.78\n",
       "2016-10-08 14:00:00           17.78\n",
       "2016-10-08 15:00:00           18.33\n",
       "2016-10-08 16:00:00           18.33\n",
       "2016-10-08 17:00:00           18.89\n",
       "2016-10-08 18:00:00           17.78\n",
       "2016-10-08 19:00:00           18.33\n",
       "2016-10-08 20:00:00           17.78\n",
       "2016-10-08 21:00:00           17.78\n",
       "2016-10-08 22:00:00           17.78\n",
       "2016-10-08 23:00:00           17.22\n",
       "2016-10-09 00:00:00           17.22\n",
       "2016-10-09 01:00:00           17.22\n",
       "2016-10-09 02:00:00           17.22\n",
       "2016-10-09 03:00:00           17.78\n",
       "2016-10-09 04:00:00           17.78\n",
       "2016-10-09 05:00:00           17.78\n",
       "2016-10-09 06:00:00           17.22\n",
       "2016-10-09 07:00:00           15.00\n",
       "2016-10-09 08:00:00           13.89\n",
       "2016-10-09 09:00:00           12.78\n",
       "2016-10-09 10:00:00           12.22\n",
       "2016-10-09 11:00:00           12.22\n",
       "2016-10-09 12:00:00           11.67\n",
       "2016-10-09 13:00:00           12.78\n",
       "2016-10-09 14:00:00           13.33\n",
       "2016-10-09 15:00:00           13.33\n",
       "...                             ...\n",
       "2018-09-12 19:00:00           27.11\n",
       "2018-09-12 20:00:00           27.70\n",
       "2018-09-12 21:00:00           27.95\n",
       "2018-09-12 22:00:00           26.38\n",
       "2018-09-12 23:00:00           25.73\n",
       "2018-09-13 00:00:00           24.68\n",
       "2018-09-13 01:00:00           23.98\n",
       "2018-09-13 02:00:00           23.64\n",
       "2018-09-13 03:00:00           23.64\n",
       "2018-09-13 04:00:00           23.44\n",
       "2018-09-13 05:00:00           23.25\n",
       "2018-09-13 06:00:00           22.80\n",
       "2018-09-13 07:00:00           22.60\n",
       "2018-09-13 08:00:00           22.45\n",
       "2018-09-13 09:00:00           22.51\n",
       "2018-09-13 10:00:00           22.60\n",
       "2018-09-13 11:00:00           22.32\n",
       "2018-09-13 12:00:00           22.79\n",
       "2018-09-13 13:00:00           22.93\n",
       "2018-09-13 14:00:00           23.32\n",
       "2018-09-13 15:00:00           23.38\n",
       "2018-09-13 16:00:00           23.70\n",
       "2018-09-13 17:00:00           24.23\n",
       "2018-09-13 18:00:00           25.04\n",
       "2018-09-13 19:00:00           25.24\n",
       "2018-09-13 20:00:00           25.24\n",
       "2018-09-13 21:00:00           25.87\n",
       "2018-09-13 22:00:00           25.16\n",
       "2018-09-13 23:00:00           24.73\n",
       "2018-09-14 00:00:00           24.19\n",
       "\n",
       "[16935 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "timeseries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your desired column(s) and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T17:13:34.721672Z",
     "start_time": "2019-06-24T17:13:34.690845Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6bbbcef5648e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtimeseries_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeseries_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'FORECAST'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtimeseries_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "timeseries_df = timeseries_df.loc[:, ['FORECAST']].dropna()\n",
    "fig, ax = plt.subplots(1, figsize=(20, 8))\n",
    "timeseries_df.plot(ax=ax)\n",
    "plt.xticks(rotation=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom in to a particular time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T19:04:18.792183Z",
     "start_time": "2018-12-13T19:04:17.645Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(20, 8))\n",
    "timeseries_df.loc['2026-01-01':'2029-01-01', :].plot(ax=ax)\n",
    "plt.xticks(rotation=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name your file and save as .csv\n",
    "The file will be available in your directory and can be downloaded to your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T19:04:18.800395Z",
     "start_time": "2018-12-13T19:04:17.649Z"
    }
   },
   "outputs": [],
   "source": [
    "to_csv(timeseries_df, \"account_forecast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T19:12:31.353117Z",
     "start_time": "2018-12-18T19:12:25.923469Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "namespace = 'na.engie.com'\n",
    "api = EWX(namespace=namespace)\n",
    "\n",
    "timeseries_df = []\n",
    "\n",
    "#example of extracting latest datasource ids \n",
    "flow_query = \"Select datasource_id,flow_timestamp,flow_type,channel_classifier_id from flow_metadata where flow_timestamp > '2018-01-01T00:00:00' ORDER BY flow_timestamp\"\n",
    "timeseries_df = api.execute_query(flow_query,limit = 10, raw_result = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "readonly": false,
  "user_home": "namespace-na_engie_com/stevenhurwitt"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}