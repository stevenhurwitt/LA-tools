{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Pluggable Rules\n",
    "This template shows how to test pluggable rules, whethere they are created by the user or used from the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Some rules use specific libraries, in principal Energyworx supports different libraries. However sometimes the Jupyter Notebook environment does not have all the neccesary libraries installed. Since each user has their own sandboxed Jupyter Notebook client environment, you can install libraries yourself. Caveat is that when a restart is done, you have to reinstall libraries. On request we can add supported libraries to the sandboxed runtime environment so after restart they will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:06:46.045227Z",
     "start_time": "2019-04-22T22:06:46.035963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import some neccesary python libraries\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from energyworx_client.storage import read_file\n",
    "from energyworx_client.client import EWX\n",
    "import unittest\n",
    "from energyworx_public.domain import KeyValueDomain, TagDomain, ChannelDomain, DatasourceDomain\n",
    "from energyworx_public import enums\n",
    "from energyworx_public.rule import AbstractRule, RuleResult, Detector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the base classes\n",
    "To inspect the documentation of the base classes you can execute the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the available in-code documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:05:12.512641Z",
     "start_time": "2019-04-22T22:05:12.499160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Detector class containing detected feature\n",
      "        Args:\n",
      "            detector (str): The name of the detector\n",
      "            function_name (str): the name of the function that holds the detector rule\n",
      "            start_timestamp (datetime): The start timestamp of the detected feature\n",
      "            end_timestamp (datetime): The end timestamp of the detected feature\n",
      "            value (str): String value of the feature\n",
      "            properties (List[dict]): Optional list of properties (key/values)\n",
      "        \n",
      "\n",
      "        Abstract implementation of the pluggable rule\n",
      "        Args:\n",
      "            datasource (Datasource):\n",
      "            dataframe (DataFrame):\n",
      "            detectors (dict):\n",
      "            source_column (str):\n",
      "            destination_column (str):\n",
      "            sequence_index (int):\n",
      "            data_filter (Series):\n",
      "            namespace (Namespace):\n",
      "        \n",
      "\n",
      "        RuleResult that contains the information that the apply function of the AbstractRule returns\n",
      "        Args:\n",
      "            result (DataFrame): the resulting dataframe\n",
      "            detectors (List[Detector]): the list of detectors\n",
      "            aggregates (List[Aggregate]): the list of Aggregate\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Check the doc string of a class, to know the attribute type\n",
    "print Detector.__init__.__doc__\n",
    "print AbstractRule.__init__.__doc__\n",
    "print RuleResult.__init__.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the available unit types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:05:30.536074Z",
     "start_time": "2019-04-22T22:05:30.521134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('enum_for_kWh: ', <UnitType.kWh: 0>)\n",
      "('enum_for_register', <DatapointType.register: 1>)\n"
     ]
    }
   ],
   "source": [
    "# Check enums for UnitType:\n",
    "def check_unit_enum(enum_class, unit):\n",
    "    \"\"\"\n",
    "    enum_class (enum class): enums.UnitType or enums.DatapointType\n",
    "    unit (str): unit to check\n",
    "    \"\"\"\n",
    "    return enums.str_to_enum(enum_class, unit, ignore_case=False)\n",
    "\n",
    "#example\n",
    "enum_for_kWh = check_unit_enum(enums.UnitType, 'kWh')\n",
    "print('enum_for_kWh: ', enum_for_kWh)\n",
    "enum_for_register = check_unit_enum(enums.DatapointType, 'register')\n",
    "print('enum_for_register', enum_for_register)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the rule class\n",
    "Below is a sample of a Rule class that is supported by our Pluggable Rules framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:13:31.957433Z",
     "start_time": "2019-04-22T22:13:31.942962Z"
    }
   },
   "outputs": [],
   "source": [
    "from energyworx_public.rule import AbstractRule, RuleResult\n",
    "from energyworx_public.domain import ChannelDomain, DatasourceDomain\n",
    "from energyworx_public import enums\n",
    "\n",
    "\n",
    "class ZeroReads(AbstractRule):\n",
    "\n",
    "    def apply(self, margin=0.01, **kwargs):\n",
    "        \"\"\"\n",
    "        Check whether the Data frame has values equal to 0 or equal to (0 + margin).\n",
    "        If there are values matching the filter they are added into a Series and returned.\n",
    "\n",
    "        Args:\n",
    "            margin (float): The margin for a value to be considered a zero value\n",
    "\n",
    "        Returns:\n",
    "            RuleResult : A Series with a flag\n",
    "                        {'margin': 0.01}\n",
    "                        or an empty Series if no flags are set\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If margin is None or a negative number\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        if margin is None or margin < 0:\n",
    "            raise TypeError('margin: [{}] is not a valid margin'.format(margin))\n",
    "\n",
    "        flag_filter = (self.dataframe[self.source_column] <= margin)\n",
    "        result = pd.Series(data=flag_filter, index=self.dataframe[flag_filter].index)\n",
    "        return RuleResult(result=result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a unittest for the rule\n",
    "To make sure the rule keeps being tested even if changes are made, you can create a unit-test. The next example shows how this can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:05:42.633395Z",
     "start_time": "2019-04-22T22:05:42.412645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from energyworx_public.domain import ChannelDomain, DatasourceDomain\n",
    "from energyworx_public import enums\n",
    "from parameterized import parameterized\n",
    "import pandas as pd\n",
    "import unittest\n",
    "\n",
    "class ZeroReadsTest(unittest.TestCase):\n",
    "    \n",
    "    def runTest(self):\n",
    "        test_annotations (self)\n",
    "    \n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        \"\"\"This function create a datasource with four channels.\"\"\"\n",
    "        self.datasource = DatasourceDomain(\n",
    "            id='id',\n",
    "            name='name',\n",
    "            description='test datasource',\n",
    "            timezone='Europe/Amsterdam',\n",
    "            channels=[\n",
    "                ChannelDomain(\n",
    "                    id='1234EKN',\n",
    "                    name='ENERGY_KWH_NORMAL',\n",
    "                    description='Test channel normal',\n",
    "                    classifier='ENERGY_KWH',\n",
    "                    unit_type=enums.UnitType(0),\n",
    "                    datapoint_type=enums.DatapointType(1),\n",
    "                    is_source=True\n",
    "                )])\n",
    "       \n",
    "    @parameterized.expand([(pd.DataFrame({\n",
    "            'ENERGY_KWH_NORMAL': [1,2,3,4,5,6,7,8,9,0] * 10},\n",
    "            index=pd.date_range(start=pd.Timestamp(2017, 1, 1),\n",
    "                                periods=100, freq='H', tz='UTC')), \n",
    "                                10) ])     \n",
    "    def test_annotations_static(self, dataframe, expected_flag_count):\n",
    "        \"\"\"Assert the count of OK flags and NOK flags to what we expect.\"\"\"\n",
    "        zero_read_rule = ZeroReads(self.datasource, dataframe=dataframe, source_column=\"ENERGY_KWH_NORMAL\", destination_column=\"zero_reads\")\n",
    "        zero_read_result = zero_read_rule.apply()\n",
    "        failed_count = zero_read_result.result.dropna().count()\n",
    "        self.assertEqual(expected_flag_count, failed_count, \"Count of \" + str(failed_count) + \" was not expected\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    suite = unittest.TestLoader().loadTestsFromModule (ZeroReadsTest())\n",
    "    unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:24:12.662297Z",
     "start_time": "2019-04-22T22:24:11.073818Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the namespace that contains the data that you have access to\n",
    "namespace_name = 'demo.energyworx.org'\n",
    "# Intialize the energyworx client\n",
    "ewx_client = EWX(namespace_id=namespace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T22:24:19.240258Z",
     "start_time": "2019-04-22T22:24:18.970768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 22:24:19,194 | WARNING | [http.py:119 - _should_retry_response] Encountered 403 Forbidden with reason \"forbidden\"\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://ewx-live.appspot.com/_ah/api/ewx/v1/query/execute?query=SELECT+STRUCT%28timestamp%2C+STRUCT%28flow_id%2C+ARRAY%5BSTRUCT%28channel_classifier_id%2C+value%2C+++++++++++++++ARRAY%28SELECT+AS+STRUCT+annotation%2C+sequence_id%2C+ARRAY_AGG%28STRUCT%28key%2C+value%29%29%29%29%5D+AS+channel%29+AS+flow%29+AS+row+++++++++++++++FROM+flows+WHERE+flow_id+IN+%28%27827f412225ed40ceaac13ca2bfa332d5%27%29+++++++++++++++AND+timestamp+%3E+%272017-01-01T00%3A00%3A00%27+AND+timestamp+%3C%3D+%272019-08-17T00%3A00%3A00%27+++++++++++++++GROUP+BY+timestamp%2C+flow_id%2C+channel_classifier_id%2C+value+ORDER+BY+timestamp%2C+flow_id+&alt=json&limit=9999 returned \"Permission denied to resource query and action GET (admin required? False)\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dd542150e9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m timeseries_df = ewx_client.execute_query(flow_query.format( flow_id='827f412225ed40ceaac13ca2bfa332d5', start_timestamp='2017-01-01T00:00:00', end_timestamp='2019-08-17T00:00:00')\n\u001b[0;32m----> 5\u001b[0;31m , limit=9999)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtimeseries_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/energyworx_client/client.pyc\u001b[0m in \u001b[0;36mexecute_query\u001b[0;34m(self, query, job_id, limit, page_token, raw_result)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjob_complete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpageToken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__execute_and_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0mjob_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobComplete'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/energyworx_client/client.pyc\u001b[0m in \u001b[0;36m__execute_and_handle_response\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msocket_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msocket_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Connection reset by peer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/oauth2client/util.pyc\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/googleapiclient/http.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://ewx-live.appspot.com/_ah/api/ewx/v1/query/execute?query=SELECT+STRUCT%28timestamp%2C+STRUCT%28flow_id%2C+ARRAY%5BSTRUCT%28channel_classifier_id%2C+value%2C+++++++++++++++ARRAY%28SELECT+AS+STRUCT+annotation%2C+sequence_id%2C+ARRAY_AGG%28STRUCT%28key%2C+value%29%29%29%29%5D+AS+channel%29+AS+flow%29+AS+row+++++++++++++++FROM+flows+WHERE+flow_id+IN+%28%27827f412225ed40ceaac13ca2bfa332d5%27%29+++++++++++++++AND+timestamp+%3E+%272017-01-01T00%3A00%3A00%27+AND+timestamp+%3C%3D+%272019-08-17T00%3A00%3A00%27+++++++++++++++GROUP+BY+timestamp%2C+flow_id%2C+channel_classifier_id%2C+value+ORDER+BY+timestamp%2C+flow_id+&alt=json&limit=9999 returned \"Permission denied to resource query and action GET (admin required? False)\">"
     ]
    }
   ],
   "source": [
    "# Getting FLOW data\n",
    "flow_query = \"SELECT STRUCT(timestamp, STRUCT(flow_id, ARRAY[STRUCT(channel_classifier_id, value, \\\n",
    "              ARRAY(SELECT AS STRUCT annotation, sequence_id, ARRAY_AGG(STRUCT(key, value))))] AS channel) AS flow) AS row \\\n",
    "              FROM flows WHERE flow_id IN ('{flow_id}') \\\n",
    "              AND timestamp > '{start_timestamp}' AND timestamp <= '{end_timestamp}' \\\n",
    "              GROUP BY timestamp, flow_id, channel_classifier_id, value ORDER BY timestamp, flow_id \"\n",
    "        \n",
    "timeseries_df = ewx_client.execute_query(flow_query.format( flow_id='827f412225ed40ceaac13ca2bfa332d5', start_timestamp='2017-01-01T00:00:00', end_timestamp='2019-08-17T00:00:00')\n",
    ", limit=9999)\n",
    "timeseries_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T16:12:07.264708Z",
     "start_time": "2019-04-23T16:12:07.255000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ZeroReadsTest testMethod=runTest>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ZeroReadTest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "ZeroReadsTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "readonly": false,
  "user_home": "namespace-na_engie_com/stevenhurwitt"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}